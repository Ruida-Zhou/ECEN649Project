{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def read_data(s, delete_name):\n",
    "    '''\n",
    "    s, <string>, which dataset to access\n",
    "    delete_name, <set>, which features do not take into account\n",
    "    '''\n",
    "    if s=='test':\n",
    "        df = pd.read_csv('pro_data_test.csv', delimiter=',')\n",
    "    elif s=='train':\n",
    "        df = pd.read_csv('pro_data_train.csv', delimiter=',')\n",
    "    else:\n",
    "        return\n",
    "    columns = df.columns\n",
    "    for column in columns:\n",
    "        if column in delete_name:\n",
    "            del df[column]\n",
    "    #print(df.head())\n",
    "    feature_len = len(df.columns)-1\n",
    "    feature = df[df.columns[0:feature_len-1]]\n",
    "    label = df[df.columns[feature_len:feature_len+1]]\n",
    "    X = feature.values\n",
    "    Y_pre = label.values\n",
    "    Y = np.zeros((len(Y_pre),1))\n",
    "    for j in range(len(Y)):\n",
    "        Y[j] = 2*(Y_pre[j]-0.5)\n",
    "    return X, Y\n",
    "delete_name = {'fnlwgt', 'capital-gain', 'capital-loss'}\n",
    "X_train, Y_train = read_data('train', delete_name)\n",
    "X_test, Y_test = read_data('test', delete_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "class SVM:\n",
    "    def __init__(self, data_len, lbd):\n",
    "        self.W = np.zeros(data_len)\n",
    "        self.b = 0\n",
    "        self.lbd = lbd\n",
    "    \n",
    "    def train(self, X, Y, eta, epsilon, batch_size):\n",
    "        batch_size = min(batch_size, len(Y))\n",
    "        \n",
    "        cnt = 0\n",
    "        sqr_sum_W = np.ones(len(self.W))\n",
    "        sqr_sum_b = 1\n",
    "        e = 1\n",
    "        \n",
    "        stop = 0\n",
    "        while True:\n",
    "            batch = random.sample(range(len(Y)), batch_size)\n",
    "            X_batch, Y_batch = X[batch], Y[batch]\n",
    "            dev_W, dev_b = self.derivative(X_batch, Y_batch)\n",
    "            sqr_sum_W = 0.9*sqr_sum_W + 0.1*dev_W*dev_W\n",
    "            sqr_sum_b = 0.9*sqr_sum_b + 0.1*dev_b*dev_b\n",
    "            \n",
    "            self.W = self.W - eta*dev_W/np.sqrt(sqr_sum_W + e*np.ones(len(self.W)))\n",
    "            self.b = self.b - eta*dev_b/np.sqrt(sqr_sum_b + e)\n",
    "            \n",
    "            if (np.dot(dev_W, dev_W) + np.dot(dev_b, dev_b))/(np.dot(self.W, self.W) + np.dot(self.b, self.b)) < epsilon:\n",
    "                break\n",
    "            \n",
    "            #if cnt==20:\n",
    "                #print(np.dot(dev_W, dev_W) + np.dot(dev_b, dev_b), self.loss(X,Y))\n",
    "            #    cnt = 0\n",
    "            #    stop = stop + 1\n",
    "            #cnt = cnt + 1\n",
    "            stop = stop + 1\n",
    "        return\n",
    "    \n",
    "    def derivative(self, X, Y):\n",
    "        dev_W = np.zeros(len(self.W))\n",
    "        dev_b = 0\n",
    "        for x, y in zip(X, Y):\n",
    "            if 1 > y*(np.dot(self.W, x) + self.b):\n",
    "                dev_W = dev_W - y*x\n",
    "                dev_b = dev_b - y\n",
    "        dev_W = dev_W / len(Y)\n",
    "        dev_b = dev_b / len(Y)\n",
    "        dev_W = dev_W + self.lbd * 2 * self.W\n",
    "        #print(dev_W, dev_b)\n",
    "        return dev_W, dev_b\n",
    "        \n",
    "    def loss(self, X, Y):\n",
    "        l = 0\n",
    "        for x, y in zip(X, Y):\n",
    "            l += max(0, 1 - y*(np.dot(self.W, x) + self.b))\n",
    "        l /= len(Y)\n",
    "        l += self.lbd * np.dot(self.W, self.W)\n",
    "        return l\n",
    "    \n",
    "    def output(self, x):\n",
    "        if np.dot(self.W, x) + self.b > 0:\n",
    "            return 1\n",
    "        else:\n",
    "            return -1\n",
    "    \n",
    "    def test(self, X, Y):\n",
    "        error = 0\n",
    "        for x, y in zip(X, Y):\n",
    "            if y!=self.output(x):\n",
    "                error = error + 1\n",
    "        return error/len(Y)\n",
    "\n",
    "# initialize svm\n",
    "lbd = 0.05\n",
    "svm = SVM(len(X_train[0]), lbd)\n",
    "\n",
    "# training svm\n",
    "epsilon = 0.005\n",
    "eta = 0.01\n",
    "batch_size = 200\n",
    "svm.train(X_test, Y_test, eta, epsilon, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8068393094289509\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:', 1-svm.test(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grads/r/ruida/python-environments/env/lib/python3.5/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# support vector machine using sklearn package\n",
    "import sklearn as skl\n",
    "clf = skl.svm.SVC(kernel='linear')\n",
    "clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8146746347941567\n"
     ]
    }
   ],
   "source": [
    "Y_pred = clf.predict(X_test)\n",
    "print('Accuracy:', skl.metrics.accuracy_score(Y_pred, Y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
